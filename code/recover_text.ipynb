{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Author:kemo\n",
    "\n",
    "Trains a captcha datasets, each captcha includes four number.\n",
    "Gets to 63.9% test accuracy after 64 epochs\n",
    "(there is still a lot of margin for parameter tuning).\n",
    "120 seconds per epoch on a Nvidia GeForce 940M GPU.\n",
    "'''\n",
    "\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "from load_data import *\n",
    "import h5py\n",
    "from keras.models import model_from_json\n",
    "\n",
    "batch_size = 128\n",
    "nb_epoch = 64\n",
    "\n",
    "MAX_CAPTCHA = 4\n",
    "CHAR_SET_LEN = 10\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 60, 160\n",
    "# number of convolutional filters to use\n",
    "nb_filters1 = 32\n",
    "nb_filters2 = 64\n",
    "nb_filters3 = 64\n",
    "# size of pooling area for max pooling\n",
    "pool_size = (2, 2)\n",
    "# convolution kernel size\n",
    "kernel_size = (3, 3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test shape: (1, 1, 60, 160)\n",
      "1 test samples\n"
     ]
    }
   ],
   "source": [
    "# the data, shuffled and split between train and test sets\n",
    "X_test = load_image(\"4_1996.jpg\")\n",
    "#(X_train, Y_train), (X_test, Y_test) = load_data(tol_num = 24000,train_num = 18000)\n",
    "\n",
    "\n",
    "X_test = X_test.reshape(X_test.shape[0], 1, img_rows, img_cols)\n",
    "input_shape = (1, img_rows, img_cols)\n",
    "\n",
    "X_test = X_test.astype('float32')\n",
    "X_test /= 255\n",
    "print('X_test shape:', X_test.shape)\n",
    "print(X_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "model = Sequential()\n",
    "\n",
    "\n",
    "# 3 conv layer\n",
    "model.add(Convolution2D(nb_filters1, kernel_size[0], kernel_size[1],\n",
    "                        border_mode='valid',\n",
    "                        input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=pool_size))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Convolution2D(nb_filters2, kernel_size[0], kernel_size[1]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=pool_size))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Convolution2D(nb_filters3, kernel_size[0], kernel_size[1]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=pool_size))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# Fully connected layer\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(MAX_CAPTCHA*CHAR_SET_LEN))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "\n",
    "# load the trained model\n",
    "model = model_from_json(open('my_model.json').read())  \n",
    "model.load_weights('my_model_weights.h5')\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adadelta',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=nb_epoch,\n",
    "      #       verbose=1, validation_data=(X_test,Y_test))\n",
    "\n",
    "\n",
    "# save model\n",
    "# json_string = model.to_json()\n",
    "# open(\"my_model.json\",\"w\").write(json_string)\n",
    "# model.save_weights('my_model_weights.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predict = model.predict(X_test,batch_size = batch_size,verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  true:  []\n",
      "0  predict:  [1, 9, 9, 6]\n",
      "predict correctly:  0\n",
      "total prediction:  1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# calculate the accuracy with the test data\n",
    "acc = 0\n",
    "for i in range(X_test.shape[0]):\n",
    "    true = []\n",
    "    predict2 = []\n",
    "    for j in range(MAX_CAPTCHA):\n",
    "        #true.append(get_max(Y_test[i,CHAR_SET_LEN*j:(j+1)*CHAR_SET_LEN]))\n",
    "        predict2.append(get_max(predict[i,CHAR_SET_LEN*j:(j+1)*CHAR_SET_LEN]))\n",
    "    if true == predict2:\n",
    "        acc+=1\n",
    "    if i<20:\n",
    "        print (i,' true: ',true)\n",
    "        print (i,' predict: ',predict2)\n",
    "print('predict correctly: ',acc)\n",
    "print('total prediction: ',X_test.shape[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
